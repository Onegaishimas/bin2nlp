"""
Decompilation Endpoints

Core API endpoints for binary decompilation and LLM translation.
Simplified architecture focusing on decompilation + translation workflow.
"""

import logging
import uuid
from datetime import datetime, timedelta
from typing import Dict, Any, Optional

from fastapi import APIRouter, File, UploadFile, Form, HTTPException, BackgroundTasks, Depends
from fastapi.responses import JSONResponse

from ...core.config import get_settings
from ...core.exceptions import (
    BinaryAnalysisException,
    UnsupportedFormatException, 
    DecompilationException,
    LLMProviderException
)
from ...core.utils import validate_file_content, calculate_file_hash
from ...cache.base import get_redis_client
from ...cache.job_queue import get_job_queue
from ...llm.providers.factory import LLMProviderFactory
from ...decompilation.engine import DecompilationEngine
from ...models.api.decompilation import (
    DecompilationRequest,
    DecompilationJobResponse, 
    DecompilationResultResponse,
    LLMProvidersResponse,
    LLMProviderInfo
)


logger = logging.getLogger(__name__)
router = APIRouter()


async def get_decompilation_engine() -> DecompilationEngine:
    """Dependency to get decompilation engine instance."""
    return DecompilationEngine()


async def get_llm_factory() -> LLMProviderFactory:
    """Dependency to get LLM provider factory."""
    factory = LLMProviderFactory()
    await factory.initialize()
    return factory


@router.post("/decompile", response_model=DecompilationJobResponse)
async def submit_decompilation(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(..., description="Binary file to decompile and translate"),
    filename: Optional[str] = Form(None, description="Override filename"),
    decompilation_depth: str = Form("standard", description="Decompilation depth (basic, standard, comprehensive)"),
    llm_provider: Optional[str] = Form(None, description="LLM provider (openai, anthropic, gemini)"),
    llm_model: Optional[str] = Form(None, description="Specific LLM model"),
    translation_detail: str = Form("standard", description="Translation detail level (brief, standard, comprehensive)"),
    include_function_translations: bool = Form(True, description="Include function translations"),
    include_import_explanations: bool = Form(True, description="Include import explanations"),
    include_overall_summary: bool = Form(True, description="Include overall summary"),
    max_functions_translate: Optional[int] = Form(None, description="Max functions to translate"),
    cost_limit_usd: Optional[float] = Form(None, description="Max LLM cost in USD"),
    timeout_seconds: Optional[int] = Form(None, description="Max processing time"),
    callback_url: Optional[str] = Form(None, description="Webhook URL for completion"),
    decompilation_engine: DecompilationEngine = Depends(get_decompilation_engine),
    llm_factory: LLMProviderFactory = Depends(get_llm_factory)
):
    """
    Submit binary file for decompilation and LLM translation.
    
    Accepts a binary file upload and configuration parameters.
    Returns job ID and tracking information for asynchronous processing.
    """
    settings = get_settings()
    
    try:
        # Read and validate file
        file_content = await file.read()\n        \n        if len(file_content) == 0:\n            raise ValueError(\"Uploaded file is empty\")\n        \n        if len(file_content) > settings.decompilation.max_file_size_mb * 1024 * 1024:\n            raise ValueError(f\"File too large. Max size: {settings.decompilation.max_file_size_mb}MB\")\n        \n        # Use provided filename or file.filename\n        actual_filename = filename or file.filename or \"unknown\"\n        \n        # Validate file format\n        file_hash = calculate_file_hash(file_content)\n        is_valid, detected_format = await validate_file_content(file_content)\n        \n        if not is_valid:\n            raise UnsupportedFormatException(f\"Unsupported file format: {detected_format}\")\n        \n        # Create decompilation request\n        request = DecompilationRequest(\n            filename=actual_filename,\n            decompilation_depth=decompilation_depth,\n            llm_provider=llm_provider,\n            llm_model=llm_model,\n            translation_detail=translation_detail,\n            include_function_translations=include_function_translations,\n            include_import_explanations=include_import_explanations,\n            include_overall_summary=include_overall_summary,\n            max_functions_translate=max_functions_translate,\n            cost_limit_usd=cost_limit_usd,\n            timeout_seconds=timeout_seconds,\n            callback_url=callback_url\n        )\n        \n        # Generate job ID\n        job_id = f\"dec_{uuid.uuid4()}\"\n        \n        # Select LLM provider if not specified\n        selected_provider = llm_provider\n        selected_model = llm_model\n        estimated_cost = None\n        \n        if not selected_provider:\n            # Auto-select best available provider\n            available_providers = llm_factory.get_healthy_providers()\n            if not available_providers:\n                raise LLMProviderException(\"No healthy LLM providers available\", \"factory\", \"NO_PROVIDERS\")\n            \n            # Simple selection - first healthy provider\n            selected_provider = available_providers[0]\n            \n        # Get provider and estimate cost\n        if selected_provider:\n            try:\n                provider = await llm_factory.get_provider(selected_provider)\n                if not selected_model:\n                    selected_model = provider.config.default_model\n                \n                # Rough cost estimation (will be refined during processing)\n                estimated_tokens = 1000  # Base estimate\n                if request.include_function_translations and request.max_functions_translate:\n                    estimated_tokens += request.max_functions_translate * 500\n                if request.include_import_explanations:\n                    estimated_tokens += 200\n                if request.include_overall_summary:\n                    estimated_tokens += 300\n                \n                estimated_cost = provider.get_cost_estimate(estimated_tokens)\n                \n            except Exception as e:\n                logger.warning(f\"Failed to get cost estimate: {e}\")\n        \n        # Store job data in Redis\n        redis_client = get_redis_client()\n        job_data = {\n            \"job_id\": job_id,\n            \"filename\": actual_filename,\n            \"file_hash\": file_hash,\n            \"file_size\": len(file_content),\n            \"detected_format\": detected_format,\n            \"request\": request.model_dump(),\n            \"selected_provider\": selected_provider,\n            \"selected_model\": selected_model,\n            \"estimated_cost\": estimated_cost,\n            \"status\": \"pending\",\n            \"created_at\": datetime.utcnow().isoformat(),\n            \"file_content\": file_content.hex()  # Store as hex string\n        }\n        \n        # Store job data with 24-hour expiry\n        await redis_client.setex(\n            f\"job:{job_id}\", \n            86400,  # 24 hours\n            str(job_data)\n        )\n        \n        # Add to job queue\n        job_queue = get_job_queue()\n        queue_position = await job_queue.enqueue_job(\n            job_id=job_id,\n            job_type=\"decompilation\",\n            priority=request.priority,\n            job_data=job_data\n        )\n        \n        # Schedule background processing\n        background_tasks.add_task(\n            process_decompilation_job,\n            job_id,\n            decompilation_engine,\n            llm_factory\n        )\n        \n        # Calculate estimated completion time\n        estimated_completion = datetime.utcnow() + timedelta(\n            seconds=request.estimated_duration_seconds + (queue_position * 30)  # 30s per queued job\n        )\n        \n        logger.info(f\"Decompilation job created: {job_id} for file {actual_filename}\")\n        \n        return DecompilationJobResponse(\n            job_id=job_id,\n            status=\"pending\",\n            filename=actual_filename,\n            estimated_duration_seconds=request.estimated_duration_seconds,\n            estimated_completion_time=estimated_completion,\n            llm_provider=selected_provider,\n            llm_model=selected_model,\n            estimated_cost_usd=estimated_cost,\n            status_url=f\"/api/v1/decompile/{job_id}\",\n            queue_position=queue_position\n        )\n        \n    except ValueError as e:\n        raise HTTPException(status_code=422, detail=str(e))\n    except UnsupportedFormatException as e:\n        raise HTTPException(status_code=422, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Failed to submit decompilation job: {e}\")\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n\n\n@router.get(\"/decompile/{job_id}\", response_model=DecompilationResultResponse)\nasync def get_decompilation_result(\n    job_id: str,\n    include_raw_data: bool = False\n):\n    \"\"\"\n    Get decompilation job status and results.\n    \n    Returns job status, progress information, and complete results\n    when processing is finished.\n    \"\"\"\n    try:\n        redis_client = get_redis_client()\n        \n        # Get job data\n        job_data_str = await redis_client.get(f\"job:{job_id}\")\n        if not job_data_str:\n            raise HTTPException(status_code=404, detail=\"Job not found\")\n        \n        # Parse job data (simplified - in real implementation would use proper serialization)\n        job_data = eval(job_data_str)  # Note: eval is unsafe - use json.loads in production\n        \n        # Get current status\n        current_status = job_data.get(\"status\", \"pending\")\n        \n        if current_status in [\"pending\", \"processing\"]:\n            # Job still in progress\n            return JSONResponse({\n                \"job_id\": job_id,\n                \"status\": current_status,\n                \"filename\": job_data.get(\"filename\"),\n                \"progress\": job_data.get(\"progress\", 0),\n                \"message\": job_data.get(\"current_step\", \"Queued for processing\")\n            })\n        \n        elif current_status == \"completed\":\n            # Job completed - return full results\n            return DecompilationResultResponse(\n                job_id=job_id,\n                status=\"completed\",\n                success=True,\n                filename=job_data[\"filename\"],\n                file_metadata=job_data.get(\"file_metadata\", {}),\n                decompilation_summary=job_data.get(\"decompilation_summary\", {}),\n                translation_summary=job_data.get(\"translation_summary\"),\n                results=job_data.get(\"results\"),\n                errors=job_data.get(\"errors\", []),\n                warnings=job_data.get(\"warnings\", []),\n                created_at=datetime.fromisoformat(job_data[\"created_at\"]),\n                started_at=datetime.fromisoformat(job_data[\"started_at\"]) if \"started_at\" in job_data else None,\n                completed_at=datetime.fromisoformat(job_data[\"completed_at\"]) if \"completed_at\" in job_data else None\n            )\n        \n        else:\n            # Job failed\n            return DecompilationResultResponse(\n                job_id=job_id,\n                status=\"failed\",\n                success=False,\n                filename=job_data[\"filename\"],\n                file_metadata=job_data.get(\"file_metadata\", {}),\n                decompilation_summary=job_data.get(\"decompilation_summary\", {}),\n                errors=job_data.get(\"errors\", [\"Processing failed\"]),\n                warnings=job_data.get(\"warnings\", []),\n                created_at=datetime.fromisoformat(job_data[\"created_at\"]),\n                started_at=datetime.fromisoformat(job_data[\"started_at\"]) if \"started_at\" in job_data else None,\n                completed_at=datetime.fromisoformat(job_data[\"completed_at\"]) if \"completed_at\" in job_data else None\n            )\n            \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Failed to get job results for {job_id}: {e}\")\n        raise HTTPException(status_code=500, detail=\"Failed to retrieve job results\")\n\n\n@router.delete(\"/decompile/{job_id}\")\nasync def cancel_decompilation_job(job_id: str):\n    \"\"\"\n    Cancel a pending or in-progress decompilation job.\n    \n    Only jobs that are pending or in early processing stages can be cancelled.\n    \"\"\"\n    try:\n        redis_client = get_redis_client()\n        \n        # Get job data\n        job_data_str = await redis_client.get(f\"job:{job_id}\")\n        if not job_data_str:\n            raise HTTPException(status_code=404, detail=\"Job not found\")\n        \n        job_data = eval(job_data_str)  # Use proper JSON in production\n        current_status = job_data.get(\"status\", \"pending\")\n        \n        if current_status in [\"completed\", \"failed\", \"cancelled\"]:\n            raise HTTPException(\n                status_code=400, \n                detail=f\"Cannot cancel job in {current_status} status\"\n            )\n        \n        # Update job status to cancelled\n        job_data[\"status\"] = \"cancelled\"\n        job_data[\"cancelled_at\"] = datetime.utcnow().isoformat()\n        \n        await redis_client.setex(f\"job:{job_id}\", 86400, str(job_data))\n        \n        # Remove from job queue if still pending\n        if current_status == \"pending\":\n            job_queue = get_job_queue()\n            await job_queue.remove_job(job_id)\n        \n        logger.info(f\"Decompilation job cancelled: {job_id}\")\n        \n        return {\"message\": f\"Job {job_id} cancelled successfully\"}\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Failed to cancel job {job_id}: {e}\")\n        raise HTTPException(status_code=500, detail=\"Failed to cancel job\")\n\n\nasync def process_decompilation_job(\n    job_id: str,\n    decompilation_engine: DecompilationEngine,\n    llm_factory: LLMProviderFactory\n):\n    \"\"\"\n    Background task to process decompilation and translation.\n    \n    This function runs the complete decompilation + LLM translation pipeline.\n    \"\"\"\n    logger.info(f\"Starting background processing for job {job_id}\")\n    \n    try:\n        redis_client = get_redis_client()\n        \n        # Get job data\n        job_data_str = await redis_client.get(f\"job:{job_id}\")\n        if not job_data_str:\n            logger.error(f\"Job data not found for {job_id}\")\n            return\n        \n        job_data = eval(job_data_str)  # Use proper JSON in production\n        \n        # Check if job was cancelled\n        if job_data.get(\"status\") == \"cancelled\":\n            logger.info(f\"Job {job_id} was cancelled, skipping processing\")\n            return\n        \n        # Update status to processing\n        job_data[\"status\"] = \"processing\"\n        job_data[\"started_at\"] = datetime.utcnow().isoformat()\n        job_data[\"progress\"] = 10\n        job_data[\"current_step\"] = \"Starting decompilation\"\n        \n        await redis_client.setex(f\"job:{job_id}\", 86400, str(job_data))\n        \n        # Get file content\n        file_content = bytes.fromhex(job_data[\"file_content\"])\n        request_data = job_data[\"request\"]\n        \n        # Phase 1: Decompilation\n        logger.info(f\"Starting decompilation phase for job {job_id}\")\n        job_data[\"progress\"] = 30\n        job_data[\"current_step\"] = \"Decompiling binary\"\n        await redis_client.setex(f\"job:{job_id}\", 86400, str(job_data))\n        \n        # TODO: Implement actual decompilation using decompilation_engine\n        # For now, create mock results\n        decompilation_results = {\n            \"functions\": [\n                {\"name\": \"main\", \"address\": \"0x401000\", \"size\": 256},\n                {\"name\": \"sub_401100\", \"address\": \"0x401100\", \"size\": 128}\n            ],\n            \"imports\": [\n                {\"library\": \"kernel32.dll\", \"function\": \"GetProcAddress\"},\n                {\"library\": \"user32.dll\", \"function\": \"MessageBoxA\"}\n            ],\n            \"strings\": [\n                {\"content\": \"Hello World\", \"address\": \"0x402000\"},\n                {\"content\": \"Error occurred\", \"address\": \"0x402020\"}\n            ]\n        }\n        \n        # Phase 2: LLM Translation\n        if job_data.get(\"selected_provider\"):\n            logger.info(f\"Starting LLM translation phase for job {job_id}\")\n            job_data[\"progress\"] = 70\n            job_data[\"current_step\"] = \"Translating to natural language\"\n            await redis_client.setex(f\"job:{job_id}\", 86400, str(job_data))\n            \n            # TODO: Implement actual LLM translation\n            # For now, create mock translation results\n            translation_results = {\n                \"overall_summary\": \"This appears to be a simple Windows console application that displays a message box to the user.\",\n                \"function_translations\": [\n                    {\n                        \"function_name\": \"main\",\n                        \"natural_language\": \"The main entry point of the program. It initializes the application and calls MessageBoxA to display a 'Hello World' message to the user.\",\n                        \"purpose\": \"Program entry point and user interaction\"\n                    }\n                ],\n                \"import_explanations\": [\n                    {\n                        \"library\": \"kernel32.dll\",\n                        \"function\": \"GetProcAddress\",\n                        \"purpose\": \"Dynamically loads function addresses from DLLs at runtime\"\n                    }\n                ]\n            }\n            \n            translation_summary = {\n                \"llm_provider\": job_data[\"selected_provider\"],\n                \"llm_model\": job_data[\"selected_model\"],\n                \"functions_translated\": len(translation_results[\"function_translations\"]),\n                \"imports_explained\": len(translation_results[\"import_explanations\"]),\n                \"overall_summary_included\": True,\n                \"tokens_used\": 1250,\n                \"cost_usd\": 0.85\n            }\n        else:\n            translation_results = None\n            translation_summary = None\n        \n        # Finalize results\n        job_data[\"status\"] = \"completed\"\n        job_data[\"completed_at\"] = datetime.utcnow().isoformat()\n        job_data[\"progress\"] = 100\n        job_data[\"current_step\"] = \"Completed\"\n        \n        job_data[\"file_metadata\"] = {\n            \"hash\": job_data[\"file_hash\"],\n            \"size_bytes\": job_data[\"file_size\"],\n            \"format\": job_data[\"detected_format\"],\n            \"platform\": \"windows\",  # TODO: Detect from decompilation\n            \"architecture\": \"x64\"   # TODO: Detect from decompilation\n        }\n        \n        job_data[\"decompilation_summary\"] = {\n            \"functions_found\": len(decompilation_results[\"functions\"]),\n            \"imports_found\": len(decompilation_results[\"imports\"]),\n            \"strings_found\": len(decompilation_results[\"strings\"]),\n            \"processing_time_seconds\": 45.2\n        }\n        \n        job_data[\"translation_summary\"] = translation_summary\n        job_data[\"results\"] = translation_results\n        job_data[\"errors\"] = []\n        job_data[\"warnings\"] = []\n        \n        # Remove file content to save space\n        del job_data[\"file_content\"]\n        \n        await redis_client.setex(f\"job:{job_id}\", 86400, str(job_data))\n        \n        logger.info(f\"Completed processing for job {job_id}\")\n        \n    except Exception as e:\n        logger.error(f\"Failed to process job {job_id}: {e}\")\n        \n        # Update job status to failed\n        try:\n            job_data[\"status\"] = \"failed\"\n            job_data[\"completed_at\"] = datetime.utcnow().isoformat()\n            job_data[\"errors\"] = [str(e)]\n            await redis_client.setex(f\"job:{job_id}\", 86400, str(job_data))\n        except:\n            logger.error(f\"Failed to update failed job status for {job_id}\")